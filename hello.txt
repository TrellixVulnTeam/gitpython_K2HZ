hello my name's Gary Sims and this is00:02Gary expense they ought to look at how00:03you can build a supercomputer using a00:06cluster of Raspberry Pi boards so trying00:09to find out more please let me explain00:14now modern-day processors our multi-core00:17processor even on a Raspberry Pi you00:18might get four cortex a53 cores in00:23smartphones there might be eight cores00:25in laptops four cores in desktops and00:28servers maybe 16 cores 32 cores just00:31depending on how much money you want to00:33spend now when you write a program that00:35has to do lots of computing intensive00:38tasks the more cores you have on that00:41process of the better so if you can00:42split up your tasks into individual00:45chunks and then you can give each core00:47that piece of data then they can work00:49individually and then come back and give00:52you a result and that's multi-threaded00:54programming now have a whole video on00:56multi processing and multi-threading and00:58multitasking and I'll leave a link to01:00that in the description below now the01:03problem is if you want to calculate01:04something that's very very complicated01:06you know predicting you know weather01:08systems or you know all kind of things01:11that they do in you know with01:12supercomputers then just having 16 cores01:15or you know even 32 cause it's not going01:18to be enough you need thousands of cores01:20and that's where a supercomputer comes01:22into a supercomputer in this context is01:25a set of individual nodes so each one is01:30a computer to boot its own operating01:32system it has a CPU multiple CPU01:34sometimes with multiple cores in them01:36okay and that they run but they're all01:38connected together so you have all these01:40nodes together and accumulatively01:42together they might have let's say you01:44know a thousand calls or or whatever it01:46is that you're aiming for now the01:48problem is when you write a program for01:49multi-threading you're running on side01:52that one computer so you compile the01:53program you run it and it runs there01:55when you have all these nodes you have01:57to have a way off the computers to talk01:59to each other and to share out this task02:01and then once they've done their02:03chatting and their processing they can02:05kind of come back and give you the02:07results so that takes a different style02:09of programming than just maybe02:11traditional multi-threaded program02:13that you might get on a on a PC or a02:16laptop and so there are three stages in02:18building a supercomputer one is you need02:20the actual hardware the second is you02:22need to actually do some setup and the02:24third is you need to write your program02:26sets look at those three stages now02:28obviously in a real world supercomputer02:30you're talking about lots and lots of02:32hardware that's got lots lots of cooling02:35and it requires a lot of electricity and02:37it costs a lot of money but you can02:38actually build the concept of the02:40supercomputer using something simple02:42like the Raspberry Pi then you don't02:44have problems with price you don't have02:46problem to the electricity bill you02:47don't have problems with heating but02:49actually you can still replicate the02:50theory and the basis behind02:53supercomputing so in this example I've02:56got myself four Raspberry Pi module02:58three boards I've got them together here03:00in this nice little rack and they are03:01all connected using USB power so it's03:04very simple to get it all up and running03:06they also all have Wireless built into03:08them that means I don't have to run an03:09Ethernet cable to each one I can do it03:11over the wireless network so once you've03:14got the hardware together the next thing03:15is to do the kind of the the setup the03:17software configuration and to do that03:19each of these boards is running a03:21raspbian and also I've done two03:23important things one is I've made sure03:25that each board can talk to the other03:27board using secure shell without a03:30password but using public and private03:34keys now I'm not going to go into how03:35you set that up now there are lots of03:37tutorials on the internet but the idea03:39is basically this you should be able to03:40copy files using SCP or login to any of03:44the nodes in your cluster using SSH with03:47private public key which means it03:48doesn't ask you for the username doesn't03:50ask you for the password it just03:51connects straight away and that's needed03:54because when all this data is flowing03:55about you need authenticated secure ways03:58of transmitting that data without you04:01having to type in passwords and worry04:02about is this message allowed to come04:04from here or not so you have to get that04:06set up first of all and the other04:08important step is you have to install04:10some kind of MPI library MPI is the04:13message passing interface and this is a04:16standard way of sending blocks of data04:18from one node in a supercomputer cluster04:21to another and there are very04:23different implementations of it I'm04:24using MPI for Python which is a way of04:27allowing MPI messages to be sent across04:30a supercomputer cluster just using the04:32Python programming language then the04:35final step is you need to write the04:36program itself now it's not like writing04:38a normal program we just go around in a04:39loop and say hey let's do this you can't04:41just say oh please magically run this on04:44all the nodes in my supercomputer you04:46need to write your program in a specific04:48way that it knows it's running in a04:50cluster and it knows it's got these04:52other knows that it can talk to and it04:54knows to send that information to then04:56it knows to gather that information back04:57in again so that it can analyze the04:59final results so what I've done is I've05:01wrote a program that allows me to check05:03if a number is a prime number or not and05:05I'm going to do that by sending out that05:07in that number to one of the nodes and05:09getting it to check it and then send the05:11answer back in fact the way it works05:13like this with four boards that means05:15I've got 16 cores with each board having05:17four cores so the MPI program sees it as05:21a sixteen node set up and what I05:23actually do is I create an array of05:25sixteen numbers and then you can say to05:27MPI please scatter that across the nodes05:30and what it will do is it will send one05:32number to each of the node which really05:34is actually four node each with four05:36cores and then at the receiving end05:39those nodes will receive that number and05:41say right this is my number I've got a05:42check if that's prime or not it will05:44check if it's prime or not and then it05:46will send back the result and so the05:47master node gathers in the number so05:49these are two of the important words for05:51MPI scatter and gather now there are05:54many actually different models in the05:56MPI setup and the different ways of05:58using them this is a simple way of05:59showing how you send out the data and06:01bring it back in again now actually if06:04you run that for just one prime number06:06it's actually really slow that's he's06:08slower than if you did it on just one no06:11and the reason for that is is to get06:12this running each of the nodes has to06:14first of all spin up and be ready to06:16receive these MPI messages you then have06:19to send the MPI messages over the06:20network it then has to do the06:22calculations then has to send the06:24messages back they have to be gathered06:25in again analyzing the results printed06:27out so the overheads of doing all that06:30just to check with a one number is prime06:32or not is really really a high06:35particular check06:36for lower numbers you know is 7 a prime06:38number well I send the message over a06:40network it works it sends it back again06:41well that'd take forever06:43compared to me just checking locally if06:45seven is a prime number or not so what06:48they my program is actually I've created06:50a huge chunk of data that maybe got a06:53thousand numbers for each of the nodes06:55and then that gets scattered across all06:58the nodes please check these 100007:00numbers then come back and give me the07:03result now even this method itself is07:05not very efficient there's a lot of07:06number you've got to send out I could07:07maybe for example send a beginning and07:10end of a range maybe that would be07:11easier but this is the way I've chosen07:13to demonstrate that you start with a big07:15chunk of data and then you scatter it07:17across the node in your supercomputer07:19finally we want all the note of process07:21a thousand numbers each they come back07:24and they tell the master node here are07:25the result and then very quickly it can07:27say well these are all the prime numbers07:29from the list that has been checked ok07:33so there's two things in quickly one is07:35this program will be available on my07:37github repository and you will find a07:39link to that in the description below07:40and now let's head over to my cluster07:43log in via the command line and let's07:46see this actually running in real life07:49ok so what we have here is for terminal07:52windows each one connected to one of the07:54four boards and the one here in the top07:56left is the first one second here on the07:59top right thurber on the bottom08:00left-hand fourth one on the bottom right08:02and what we're going to do is show you08:03that each one is basically not doing08:05anything to idle you can see here the08:07full processor cause each one is pretty08:09much doing nothing so what would they do08:12first of all is I'm going to show you08:13that I have here a program written in08:18Python okay that is actually you'll find08:21it on every single note if we get any08:23hit a number 4 for example we can do08:24exactly the same thing and we can see08:27that the same script is there and that08:30means that it when it runs across the08:32supercomputer nodes the same script is08:34run on each of the 4 different machines08:37will put this on back now into H top ok08:40and so the first thing we're gonna do is08:41we're gonna run this script just on one08:43node ok and the way you do that is you08:47use this HP08:49a mpi exec program the time but here at08:53the beginning is a way of seeing how08:54long it runs and then it says basically08:56run Python and then this program I just08:58showed you to run now just on one09:00Raspberry Pi so notice it says there are09:03only four cores okay and it's starting09:05to find the prime number and if we look09:07here the other device if we can see09:08their activity has remained zero very09:12idle there's nothing going on and this09:14will take about 30 seconds or so to09:16complete as it finds all the different09:18things in the other and three nodes here09:20are doing nothing is all happening just09:22on this one node so it's about to come09:24to its completion now and we'll see how09:26long that took 90 mm prime numbers found09:30so far hundred one thousand found it09:33should five hundred and nine thousand09:35nine hundred took 33 seconds okay so09:38that's what it does if you run it on09:39just four cores on one Raspberry Pi09:42board now before you run it on the09:45cluster you have to define a file which09:47I have called cluster file which has got09:48the four names of the different the IP09:51address of the different clusters so09:53here we can see 33 43 53 and 47 so here09:57if I do an IP address show W land 0 we10:03can see here that this is 47 number 4710:07which the last one here if we go down10:08here to this bottom one here in the10:10bottom right hand corner and run the10:11same command IP address wlan0 we can see10:16here that this is 53 okay and the other10:20two are also listed as in that cluster10:23file ok so now we want to run it across10:25all the different node in the cluster so10:27what we do is we use this command the10:29same e an MPI exec but now notice we10:31have this pit here the talks about host10:34file cluster file which points it to10:36that file I created with those lists of10:38IP addresses ok so now when we run this10:42we will be able to see that it runs10:43across all the different nodes let's10:45just fire that off and the first thing10:47to notice notice now the other devices10:49here the other boards all starting to10:51run at 100% as they are being used10:53notice how it now says total calls 1610:56because running across all of the10:58different things if you look here on10:59this one for example you can see these11:01first four tasks11:03the Python Tarson there it has is11:04finished and it finished in 16 seconds11:07okay so that was twice as fast now some11:10of that is because of the overhead if11:12this was running for much longer for11:13several minutes for several hours then11:15that overhead would become negligible11:18but what we saw was that by running it11:20across all four nodes in the cluster11:22using 16 cores we got a much much faster11:26time and that is the essence of how you11:29run to super computer programs okay so11:32there you have it there you saw the11:33program running there and you saw that11:34it is quicker using the cluster I'm sure11:37I could actually make it more efficient11:38to make it even quicker on the cluster11:40and it would gain efficiency even more11:42so you've got to even bigger numbers but11:44that's how supercomputers work and so it11:47no matter how complicated the task you11:49still have to break it down into smaller11:51tasks and those smaller tasks are run on11:53the individual nodes in your huge11:55supercomputer and of course you could11:57build a computer much more powerful you11:59could do this using pcs you could do12:01this using laptops but of course then12:03you do have the issues of cost12:04electricity and of cooling whereas if12:06you do this with four raspberry PI's12:08even ten raspberry PI's or twenty12:10raspberry PI's you get the idea of how12:12to distribute the tasks across many many12:14nodes and then you can verify that and12:16then one day if you do actually get12:17access to a real supercomputer you can12:19run that program on there and see how12:21quickly it really does run okay that's12:24it my name's Gary Sims this is Gary12:25explained already hope you enjoyed this12:26video if did please do give a thumbs up12:28don't forget to subscribe and that's it12:30I'll see the next one